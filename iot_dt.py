# -*- coding: utf-8 -*-
"""iot_DT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hCkMxqDPaZ6lpkcsKIdegLobJH9f96N-
"""

from google.colab import drive
import sys
import os
drive.mount('/content/drive')
sys.path.append('drive')
os.chdir('/content/drive/MyDrive/Colab_Notebooks')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

dataset1 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/csv/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
dataset2 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/csv/part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
dataset3 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/csv/part-00002-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
dataset4 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/csv/part-00003-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
dataset5 = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/csv/part-00004-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
frames = [dataset1, dataset2, dataset3, dataset4, dataset5]
dataset = pd.concat(frames)
dataset.head(5)

dataset.columns

print(dataset['label'].value_counts())

dataset.info()

dataset.shape

dataset.describe()

lst = list(dataset['label'].unique())
print(lst)

dataset['label'].astype(str)

sns.countplot(data=dataset, y='label')

plt.figure(figsize=(48,15), dpi=200)
sns.heatmap(dataset.corr(), annot=True, cmap='viridis_r')

def create_label_map(dataset):
    unique_labels = sorted(dataset['label'].unique())
    label_map = {label: idx+1 for idx, label in enumerate(unique_labels)}
    return label_map

label_map = create_label_map(dataset)
print(label_map)

dataset['label'] = dataset['label'].map(label_map)
dataset.head(5)

correlation_matrix = dataset.corr(numeric_only=True)
correlation_matrix

# Exclude autocorrelation and get the top n highest correlated attributes
n = 46  # Set the number of attributes you want to display
top_corr = correlation_matrix['label'].drop('label').nlargest(n)
#top_corr
# Add the 'label' attribute as the center of the correlation
top_corr = pd.concat([top_corr, correlation_matrix['label'].drop('label')])
top_corr

top_corr = pd.DataFrame(top_corr)
top_corr

plt.figure(figsize=(10, 10))

# Create the heatmap
sns.heatmap(top_corr.head(46), annot=True, cmap="RdBu", fmt=".1f", square=True)

# Display the heatmap
plt.show()

# Split data into x(input) and y(output)
top_n_attributes = list(top_corr.index)[:n]
X = dataset[top_n_attributes]
y = dataset['label']
#print(y)
top_n_attributes

X.head()

print(X.shape)
print(y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion='entropy', max_depth=50, min_samples_split=35)

clf.fit(X_train, y_train)

# save the model to disk
with open('model.pkl','wb') as f:
    pickle.dump(clf,f)

# load
with open('model.pkl', 'rb') as f:
    clf2 = pickle.load(f)

pred = clf.predict(X_test)
pred

from sklearn.metrics import classification_report, ConfusionMatrixDisplay
print(classification_report(y_test, pred))

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, pred))

datatest = pd.read_csv("/content/drive/MyDrive/Colab_Notebooks/csv/part-00025-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv")
test = datatest[top_n_attributes]
datatest.head()

new_pred = clf2.predict(test)
new_pred

value = {
    'true_label' : datatest['label'],
    'actual_label' : datatest['label'].map(label_map),
    'predicted_label' : new_pred,
}

compare = pd.DataFrame(value)

compare.head(40)